{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "153bf8fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from scipy.interpolate import interp1d\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "import plotly.colors\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tqdm\n",
    "\n",
    "from mvf_bto.data_loading import load_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "399af5af",
   "metadata": {},
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da1525d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_path = \"/Users/anoushkabhutani/PycharmProjects/10701-mvf-bto/data/2017-05-12_batchdata_updated_struct_errorcorrect.mat\"\n",
    "data_path = \"/home/amalss/Documents/CMU/Courses/10701/project/data/2017-05-12_batchdata_updated_struct_errorcorrect.mat\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a26f9c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_data(file_path= data_path, num_cells= 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa30d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "single_cell_data = data['b1c2']['cycles']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43e44118",
   "metadata": {},
   "source": [
    "## Preprocessing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca8e318",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = []\n",
    "max_cycle = 1175\n",
    "for cycle_key, time_series in tqdm.tqdm(single_cell_data.items()):\n",
    "    cycle_num = int(cycle_key)\n",
    "    if cycle_num<1:\n",
    "        continue\n",
    "    df = pd.DataFrame({'t': time_series['t'], \n",
    "                       'V': time_series['V'],\n",
    "                       'temp': time_series['T'],\n",
    "                       'I': time_series['I'],\n",
    "                       'Qd': time_series['Qd'],\n",
    "                      }\n",
    "                       )\n",
    "    # drop duplicates to be able to interpolate over capacity\n",
    "    df = df.drop_duplicates(subset='Qd')\n",
    "    \n",
    "    \n",
    "    # get discharge part of curve only (current is negative during discharge)\n",
    "    df = df[df.I<-3.85]\n",
    "    \n",
    "    # normalize voltage and temperature using fixed thershold's to avoid data leakage\n",
    "    df['V_norm'] = (df.V-1.9)/(3.5-1.9)\n",
    "    df['T_norm'] = (df.temp-24)/(38-24)\n",
    "    \n",
    "    interp_df = pd.DataFrame()\n",
    "    # use capacity as reference to interpolate over\n",
    "    Q_eval = [0, 0.0125, 0.025, 0.075, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.8, 0.85, 0.9, 0.95, 0.975, 0.98, 0.99, 1.0, 1.005, 1.01, 1.015, 1.02]\n",
    "    interp_df['Q_eval'] = Q_eval\n",
    "    fV = interp1d(x=df.Qd, y =df.V_norm, kind='quadratic', fill_value='extrapolate')\n",
    "    interp_df['V_norm'] = fV(Q_eval)\n",
    "    ft = interp1d(x=df.Qd, y =df.t, kind='quadratic', fill_value='extrapolate')\n",
    "    interp_df['t'] = ft(Q_eval)\n",
    "    fT = interp1d(x=df.Qd, y =df['T_norm'], kind='quadratic', fill_value='extrapolate')\n",
    "    interp_df['T_norm'] = fT(Q_eval)\n",
    "    \n",
    "    interp_df['Cycle'] = [cycle_num/max_cycle for i in range(len(interp_df))]\n",
    "    \n",
    "    df_list.append(interp_df)\n",
    "print(len(Q_eval))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbf38f7d",
   "metadata": {},
   "source": [
    "## What does raw versus interpolated data look like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be06bb8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = go.Figure()\n",
    "# fig.add_trace(go.Scatter(x = df.Qd, y = df.V_norm, showlegend=True, mode=\"markers\", name=\"Raw\"))\n",
    "# fig.add_trace(go.Scatter(x = interp_df.Q_eval, y = interp_df.V_norm, showlegend=True, mode=\"markers+lines\" , name=\"Interpolated\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdbbbd83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# multivariate data preparation\n",
    "# TODO: multi output (temperature + voltage) (Hancheng)\n",
    "# TODO: multiple time steps in the future \n",
    "X_list, y_list = [], []\n",
    "\n",
    "# split a multivariate sequence into samples\n",
    "def split_sequences(sequences, n_steps, nf_steps):\n",
    "    X, y = list(), list()\n",
    "    for i in range(len(sequences)-nf_steps-n_steps+1):#-nf_steps-n_steps+1\n",
    "        # find the end of this pattern\n",
    "        end_ix = i + n_steps\n",
    "        # check if we are beyond the dataset\n",
    "        if end_ix > len(sequences):\n",
    "            break\n",
    "            # gather input and output parts of the pattern\n",
    "        seq_x, seq_y = sequences[i:end_ix-1, :-1], [sequences[end_ix+j-1, -1] for j in np.arange(nf_steps)]#sequences[end_ix-1, -1]#\n",
    "        X.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "for df in df_list:\n",
    "    # define input sequence\n",
    "    in_seq1 = df['T_norm'].values\n",
    "    in_seq2 = df['Q_eval'].values\n",
    "    in_seq3 = df['V_norm'].values\n",
    "    in_seq4 = df['Cycle'].values\n",
    "    out_seq = df['V_norm'].values\n",
    "\n",
    "    #Set number of steps into the future to predict\n",
    "    nf_steps = 2\n",
    "    \n",
    "    # convert to [rows, columns] structure\n",
    "    in_seq1 = in_seq1.reshape((len(in_seq1), 1))\n",
    "    in_seq2 = in_seq2.reshape((len(in_seq2), 1))\n",
    "    in_seq3 = in_seq3.reshape((len(in_seq3), 1))\n",
    "    in_seq4 = in_seq4.reshape((len(in_seq4), 1))#cycle\n",
    "    out_seq = out_seq.reshape((len(out_seq), 1))\n",
    "    \n",
    "    # horizontally stack columns\n",
    "    dataset = np.hstack((in_seq1, in_seq2, in_seq3, in_seq4, out_seq))\n",
    "    \n",
    "    # choose a number of time steps (for input window)\n",
    "    n_steps = 4\n",
    "    \n",
    "    # convert into input/output\n",
    "    X_cycle, y_cycle = split_sequences(dataset, n_steps, nf_steps)\n",
    "    # print(y_cycle.shape)\n",
    "    X_list.append(X_cycle)\n",
    "    y_list.append(y_cycle)\n",
    "\n",
    "# print(np.array(X_list).shape, np.array(y_list).shape)\n",
    "# print(y_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06da13c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = X_cycle.shape[0] \n",
    "print(batch_size)\n",
    "# batch_size must be equal to the length of 1 input curve\n",
    "# since for a stateful LSTM the cell state is cleared after a batch\n",
    "# (look at the keras docs)\n",
    "# we could write over own custom callback if we need batch_size != sequence_length\n",
    "# (for the use t prediction as t+1 input case)\n",
    "# but I'm not sure if that's acceptable practice\n",
    "\n",
    "window_length = X_cycle.shape[1]\n",
    "n_features = X_cycle.shape[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ae46c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array([item for index, item in enumerate(X_list) if index % 100 != 0])\n",
    "X_test = np.array([item for index, item in enumerate(X_list) if index % 100 == 0])\n",
    "\n",
    "# y_train = np.array([[y_list[idx] for idx in np.arange(index, index + nf_steps)] for index, item in enumerate(y_list) if (index % 100 != 0) and (index < len(y_list) - nf_steps + 1)])\n",
    "# y_train = np.array([[y_list[idx] for idx in np.arange(index, index + nf_steps)] for index, item in enumerate(y_list) if (index % 100 == 0) and (index < len(y_list) - nf_steps + 1)])\n",
    "y_train = np.array([item for index, item in enumerate(y_list) if index % 100 != 0])\n",
    "y_test = np.array([item for index, item in enumerate(y_list) if index % 100 == 0])\n",
    "\n",
    "# y_test = y_test.flatten()\n",
    "# y_train = y_train.flatten()\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0]*batch_size, X_train[0].shape[1] , X_train.shape[-1])\n",
    "X_test = X_test.reshape(X_test.shape[0]*batch_size,X_test[0].shape[1], X_test.shape[-1])\n",
    "\n",
    "y_train = y_train.reshape(y_train.shape[0]*batch_size, y_train.shape[-1])\n",
    "y_test = y_test.reshape(y_test.shape[0]*batch_size, y_test.shape[-1])\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c19b540",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_weight = np.ones(y_train.shape)\n",
    "\n",
    "# TODO: experiment with different sample weights and thersholds\n",
    "# (this is a arbitary guess)\n",
    "sample_weight[y_train<0.6]=2\n",
    "sample_weight[y_train<0.5]=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b682e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model\n",
    "# TODO: hyperparameter tuning (Anoushka)\n",
    "model = Sequential()\n",
    "model.add(LSTM(32, return_sequences=True, stateful=True, batch_input_shape=(batch_size, 3, 4)))\n",
    "model.add(LSTM(16, return_sequences=False))\n",
    "model.add(Dense(32, activation=\"sigmoid\"))\n",
    "model.add(Dense(8))\n",
    "# need to change here (maybe) if n steps into the future\n",
    "model.add(Dense(nf_steps))\n",
    "\n",
    "model.compile(optimizer='adam', loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf88951-cc4e-4417-b441-506e23a665da",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cacd6530",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: add validation set or validation split + early stopping\n",
    "n_epochs = 50\n",
    "print(X_train.shape, y_train.shape)\n",
    "history = model.fit(X_train, y_train, \n",
    "                    epochs=n_epochs, \n",
    "                    batch_size=batch_size, \n",
    "                    shuffle=False, \n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad3d04e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = go.Figure()\n",
    "# fig.add_trace(go.Scatter(x = np.linspace(1,50), y = history.history['loss'],\n",
    "#                          showlegend=False, mode=\"markers+lines\"))\n",
    "# fig.update_xaxes(title='Epochs')\n",
    "# fig.update_yaxes(title='Loss (MSE)')\n",
    "\n",
    "#Matplotlib code\n",
    "import matplotlib.pyplot as plt \n",
    "plt.plot(np.arange(n_epochs), history.history['loss'])\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss (MSE)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d3a7908",
   "metadata": {},
   "source": [
    "## Parity Plot of Training Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c40418d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# random plotting traing error at some interval = skip to not make the plot rendering too slow\n",
    "skip = 50\n",
    "\n",
    "# fig = go.Figure()\n",
    "# fig.add_trace(go.Scatter(x = [0,1], y = [0,1], showlegend=False, mode=\"markers+lines\"))\n",
    "# for i in range(0,len(X_train), batch_size*skip):\n",
    "#     fig.add_trace(go.Scatter(x = model.predict(X_train[i:i+batch_size],verbose=0).flatten(), \n",
    "#                              y = y_train[i:i+batch_size], \n",
    "#                              showlegend=False, mode=\"markers+lines\"))\n",
    "# fig.update_yaxes(title='Normalized Target')\n",
    "# fig.update_xaxes(title='Normalized Prediction')\n",
    "\n",
    "#Matplotlib code\n",
    "plt.plot([0, 1], [0, 1], color='black')\n",
    "# print(y_train[0:batch_size])\n",
    "# print(model.predict(X_train[i:i+batch_size], verbose=0))\n",
    "for i in range(0, len(X_train), batch_size*skip):\n",
    "    for j in range(nf_steps):\n",
    "        plt.plot(model.predict(X_train[i:i+batch_size], verbose=0)[:, j],\n",
    "                 y_train[i:i+batch_size][:, j], label=f\"{i}\")\n",
    "\n",
    "plt.xlabel(\"Normalized target\")\n",
    "plt.ylabel(\"Normalized prediction\")\n",
    "# plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a26ace94",
   "metadata": {},
   "source": [
    "## Parity Plot of Test Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3bd3873",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pallete = plotly.colors.qualitative.Dark24*10\n",
    "\n",
    "# fig = go.Figure()\n",
    "# fig.add_trace(go.Scatter(x = [0,1], y = [0,1], showlegend=False, mode=\"markers+lines\"))\n",
    "\n",
    "# for i in range(0, len(X_test), batch_size):\n",
    "#     fig.add_trace(go.Scatter(x = model.predict(X_test[i:i+batch_size],verbose=0).flatten(), \n",
    "#                              y = y_test[i:i+batch_size], \n",
    "#                              showlegend=False, mode=\"markers+lines\", name='batch',\n",
    "#                              line_color = pallete[i]))\n",
    "# fig.update_yaxes(title='Normalized Target')\n",
    "# fig.update_xaxes(title='Normalized Prediction')\n",
    "\n",
    "#Matplotlib code\n",
    "plt.plot([0, 1], [0, 1], color='black')\n",
    "for i in range(0, len(X_test), batch_size):\n",
    "    for j in range(nf_steps):\n",
    "        plt.plot(model.predict(X_test[i:i+batch_size], verbose=0)[:, j],\n",
    "                 y_test[i:i+batch_size][:, j], label=f\"{i}\")\n",
    "\n",
    "plt.xlabel(\"Normalized target\")\n",
    "plt.ylabel(\"Normalized prediction\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a02331f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = go.Figure()\n",
    "# for i in range(0, len(X_test), batch_size):\n",
    "#     V_actual = y_test[i:i+batch_size]\n",
    "#     V_pred = model.predict(X_test[i:i+batch_size],verbose=0).flatten()\n",
    "#     fig.add_trace(go.Scatter(x = Q_eval, y = V_actual*(3.5-1.9)+1.9, \n",
    "#                              mode='lines', name = 'data', \n",
    "#                              line_color = pallete[i]))\n",
    "#     fig.add_trace(go.Scatter(x = Q_eval, y = V_pred*(3.5-1.9)+1.9,\n",
    "#                              mode='markers', name = 'prediction', \n",
    "#                              line_color = pallete[i]))\n",
    "# fig.update_yaxes(title=\"Voltage [V]\")\n",
    "# fig.update_xaxes(title=\"Capacity [Ah]\")\n",
    "\n",
    "# Matplotlib code\n",
    "print(batch_size)\n",
    "N = len(Q_eval) - batch_size\n",
    "shift = nf_steps - 1\n",
    "for i in range(0, len(X_test), batch_size):\n",
    "    if i == 187:\n",
    "        V_actual = y_test[i:i+batch_size]\n",
    "        V_pred = model.predict(X_test[i:i+batch_size],verbose=0)\n",
    "        plt.plot(Q_eval[N-nf_steps:-nf_steps], V_actual[:, 0]*(3.5-1.9)+1.9, label=f\"data-{i}\")\n",
    "        plt.scatter(Q_eval[N:], V_pred[:, 0]*(3.5-1.9)+1.9, label=f\"pred-{i} - 1\", color='black')\n",
    "        plt.scatter(Q_eval[N + shift:], V_pred[:, 1][:-1*shift]*(3.5-1.9)+1.9, label=f\"pred-{i} - 2\", color='red')\n",
    "        break\n",
    "plt.ylabel(\"Voltage [V]\")\n",
    "plt.xlabel(\"Capacity [Ah]\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfb40e62-74f7-45d9-864a-8cc6731f35a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
